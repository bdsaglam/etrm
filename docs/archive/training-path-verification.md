# ETRM Training Path Verification

**Date**: January 12, 2026
**Purpose**: Verify all modules, configs, and scripts are correctly connected

---

## Training Path Overview

```
jobs-etrm-semi-final.txt
    │
    ├─ Command: torchrun ... pretrain_etrm.py --config-name cfg_pretrain_etrm_arc_agi_1
    │
    ▼
pretrain_etrm.py (Entry Point)
    │
    ├─ Hydra decorator: @hydra.main(config_name="cfg_pretrain_etrm_arc_agi_1")
    │
    ▼
config/cfg_pretrain_etrm_arc_agi_1.yaml
    │
    ├─ defaults: - arch: etrm
    │
    ▼
config/arch/etrm.yaml
    │
    ├─ name: recursive_reasoning.etrm@TRMWithEncoder
    │
    ▼
models/recursive_reasoning/etrm.py
    │
    └─ class TRMWithEncoder(nn.Module)
```

---

## Step-by-Step Verification

### 1. Job File Entry Point ✅

**File**: `jobs-etrm-semi-final.txt`

**Example Command** (SF1):
```bash
torchrun --nproc-per-node 4 \
    pretrain_etrm.py \
    --config-name cfg_pretrain_etrm_arc_agi_1 \
    +project_name="etrm-semi-final" \
    +run_name="SF1_hybrid_std_baseline" \
    arch.encoder_type=hybrid_standard \
    arch.encoder_num_layers=4 \
    arch.halt_max_steps=16 \
    arch.halt_exploration_prob=0.5 \
    global_batch_size=128 \
    epochs=1000 \
    eval_interval=200
```

**Verified**:
- ✅ Script exists: `pretrain_etrm.py`
- ✅ Config exists: `config/cfg_pretrain_etrm_arc_agi_1.yaml`
- ✅ Correct training mode (dynamic halting, not fixed steps)

---

### 2. Training Script ✅

**File**: `pretrain_etrm.py`

**Key Properties**:
```python
@hydra.main(config_path="config", config_name="cfg_pretrain_etrm_arc_agi_1", version_base=None)
def launch(hydra_config: DictConfig):
    # Initialize distributed training
    # Load config
    config = load_synced_config(hydra_config, rank=RANK, world_size=WORLD_SIZE)

    # Create model
    model = create_model_encoder(config, train_metadata, rank, world_size)

    # Training loop with dynamic ACT halting
    for epoch in range(config.epochs):
        metrics, batch_out, preds_out = train_batch_encoder_original(...)
```

**Verified**:
- ✅ Hydra decorator references correct config
- ✅ Uses `train_batch_encoder_original()` for dynamic halting
- ✅ No references to old `pretrain_encoder.py` (fixed steps approach)

---

### 3. Main Config ✅

**File**: `config/cfg_pretrain_etrm_arc_agi_1.yaml`

**Key Settings**:
```yaml
defaults:
  - arch: etrm          # Loads config/arch/etrm.yaml
  - _self_

arch:
  encoder_type: standard
  encoder_num_layers: 2
  halt_exploration_prob: 0.5
  halt_max_steps: 16

data_paths: ["data/arc1concept-encoder-aug-1000"]
evaluators:
  - name: arc@ARC

global_batch_size: 256
epochs: 100000
lr: 1e-4
grad_clip_norm: 1.0
```

**Verified**:
- ✅ Arch default points to `etrm` (not `trm_encoder`)
- ✅ Uses encoder-mode preprocessed data
- ✅ Gradient clipping enabled (1.0)
- ✅ Dynamic halting parameters present

---

### 4. Architecture Config ✅

**File**: `config/arch/etrm.yaml`

**Key Settings**:
```yaml
name: recursive_reasoning.etrm@TRMWithEncoder
loss:
  name: losses@ACTLossHead
  loss_type: stablemax_cross_entropy
  kl_weight: 0.0001  # KL divergence weight for variational encoders

encoder_type: standard
encoder_num_layers: 2
encoder_pooling_method: mean

# ACT settings - DYNAMIC HALTING
halt_exploration_prob: 0.5   # Exploration during training
halt_max_steps: 16           # Max steps before forced halt

# TRM architecture
H_cycles: 3
L_cycles: 6
H_layers: 0
L_layers: 2
hidden_size: 512
num_heads: 8
```

**Verified**:
- ✅ References `etrm` module (not `etrm_original`)
- ✅ Dynamic halting enabled (not fixed num_act_steps)
- ✅ KL loss available for variational encoders
- ✅ ACT exploration probability configured

---

### 5. Model Implementation ✅

**File**: `models/recursive_reasoning/etrm.py`

**Key Classes**:
```python
class TRMWithEncoder(nn.Module):
    def __init__(self, cfg):
        # Create encoder (standard, hybrid_standard, hybrid_variational)
        self.encoder = create_encoder(cfg)

        # Create TRM inner model
        self.inner = TRMInnerModel(...)

    def forward(self, batch, carry=None):
        if self.training:
            return self._forward_train_original(batch, carry)
        else:
            return self._forward_eval(batch)

    def _forward_train_original(self, batch, carry):
        """DYNAMIC HALTING during training"""
        for step in range(max_steps):
            # Encoder RE-ENCODES every step (full gradients)
            context = self.encoder(batch.demos)

            # TRM reasoning step
            new_carry, logits, halt = self.inner.step(...)

            # Dynamic halting with exploration
            if should_halt(halt, exploration_prob):
                break

        return outputs, new_carry
```

**Verified**:
- ✅ `TRMWithEncoder` class exists (line 351)
- ✅ Uses `_forward_train_original()` for dynamic halting
- ✅ Encoder called every step (no caching)
- ✅ Exploration probability controls random halting

---

## Experiment Matrix

All 6 semi-final experiments follow the same path:

| Exp | Arch Type | Layers | Explore | Batch | Config |
|-----|-----------|--------|---------|-------|--------|
| SF1 | hybrid_standard | 4 | 0.5 | 128 | cfg_pretrain_etrm_arc_agi_1 |
| SF2 | hybrid_standard | 4 | 0.7 | 128 | cfg_pretrain_etrm_arc_agi_1 |
| SF3 | hybrid_variational | 4 | 0.5 | 128 | cfg_pretrain_etrm_arc_agi_1 |
| SF4 | hybrid_variational | 4 | 0.7 | 128 | cfg_pretrain_etrm_arc_agi_1 |
| SF5 | standard | 2 | 0.5 | 256 | cfg_pretrain_etrm_arc_agi_1 |
| SF6 | standard | 2 | 0.7 | 256 | cfg_pretrain_etrm_arc_agi_1 |

All use:
- ✅ `pretrain_etrm.py` script
- ✅ `cfg_pretrain_etrm_arc_agi_1` config
- ✅ `etrm` architecture with dynamic halting

---

## Module Name Cleanup

### ✅ Correctly Renamed

| Old Name | New Name |
|----------|----------|
| `pretrain_encoder_original.py` | `pretrain_etrm.py` |
| `models/recursive_reasoning/etrm_original.py` | `models/recursive_reasoning/etrm.py` |
| `config/arch/trm_encoder_original.yaml` | `config/arch/etrm.yaml` |
| `cfg_pretrain_encoder_original_arc_agi_1.yaml` | `cfg_pretrain_etrm_arc_agi_1.yaml` |

### ✅ Removed (Approach 2 - Fixed Steps)

| Removed File | Reason |
|--------------|--------|
| `pretrain_encoder.py` | Fixed ACT steps (approach 2) |
| `cfg_pretrain_encoder.yaml` | Approach 2 config |
| `trm_encoder.yaml.fixed_steps` | Approach 2 arch backup |

---

## Critical Differences: Approach 2 vs Approach 3

| Aspect | Approach 2 (Removed) | Approach 3 (Active) |
|--------|---------------------|---------------------|
| **Script** | `pretrain_encoder.py` | `pretrain_etrm.py` |
| **Model** | `etrm.py` (fixed) | `etrm.py` (dynamic) |
| **ACT Steps** | Fixed `num_act_steps=4` | Dynamic halting (2-16 steps) |
| **Forward** | Loop `num_act_steps` times | One forward per batch, carry persists |
| **Encoder** | Cached after first step | Re-encodes every step |
| **Training** | Online learning mode | Original TRM mode |

---

## Verification Status

✅ **All components verified and working correctly**

1. ✅ Job files reference correct script and config
2. ✅ Training script has correct Hydra decorator
3. ✅ Config hierarchy loads properly
4. ✅ Architecture config references correct module
5. ✅ Model class exists and is properly structured
6. ✅ Dynamic ACT halting implemented correctly
7. ✅ No references to old fixed-steps approach remain

---

## Expected Behavior

When SF1-SF6 run:

1. **Loading**: Hydra loads `cfg_pretrain_etrm_arc_agi_1.yaml`
2. **Model**: Creates `TRMWithEncoder` with specified encoder type
3. **Training**: Uses dynamic halting with exploration
4. **ACT Steps**: Should vary 2-16 steps during training (oscillating)
5. **Gradients**: Full encoder gradient coverage every step
6. **Evaluation**: Majority voting across ~912 augmented versions

**Key Metrics to Monitor**:
- `train/steps` - Should vary (not fixed at 4!)
- `train/q_halt_accuracy` - Should reach ~95%+
- `grad/encoder_norm` - Should be > 0.1 (healthy)
- `train/encoder_cross_sample_var` - Variance indicates diversity

---

## Success Criteria

Training is successful when:
- ✅ ACT steps oscillate between 2-16 (not constant)
- ✅ Training accuracy increases over epochs
- ✅ Gradient flow is healthy (encoder_norm > 0.1)
- ✅ Q-halt accuracy improves (learns when to stop)
- ✅ No reference to "fixed num_act_steps" behavior
