# ARC Prize 2024: Technical Report

**Paper**: arXiv 2412.04604v2
**Authors**: François Chollet, Mike Knoop, Gregory Kamradt, Bryan Landers
**Year**: 2024 (Published January 9, 2025)

## TL;DR
ARC Prize 2024 catalyzed a major breakthrough in ARC-AGI performance from 33% to 55.5% on the private evaluation set through three key approaches: deep learning-guided program synthesis, test-time training (TTT), and hybrid combinations of both. The competition revealed that classical deep learning paradigms fail completely on ARC-AGI (max 11% without TTT), while test-time adaptation and program synthesis are essential for generalization to novel tasks.

## Key Findings
- **State-of-the-art increased dramatically**: From 33% (pre-2024) to 55.5% (MindsAI, closed) and 53.5% (the ARChitects, open-source)
- **Classical deep learning fails**: No static inference transduction solution scores above 11% - a stark gap highlighting inability to generalize to novel tasks
- **TTT is essential for LLM approaches**: All top LLM-based solutions use test-time training; none without it exceed 11%
- **Induction vs transduction solve different tasks**: Each approach tackles distinct problem types, requiring ensemble methods to reach SOTA
- **Algorithmic improvements matter more than compute**: Public leaderboard (1000x more compute, $10K budget) tracked closely with Kaggle leaderboard ($10 budget), suggesting massive compute isn't necessary
- **Program synthesis still competitive**: Brute-force DSL search scores ~40%, comparable to LLM-guided synthesis with similar compute
- **Data augmentation critical**: Success requires synthetic data (Re-ARC, ARC-Heavy) and careful augmentations due to limited dataset size
- **2024 = paradigm shift**: First time transduction-based approaches scored above 0% (late 2023), then rapidly scaled to compete with program synthesis

## Taxonomy of Approaches

### 1. Deep Learning-Guided Program Synthesis
**Goal**: Generate or search for programs that solve tasks

**Flavors**:
- **Brute-force DSL search**: Exhaustive search over Domain Specific Language
  - Scores: ~40% on private eval (Agnis Liukis)
  - Limitation: Combinatorial explosion
  - Historical note: 49% achievable by ensembling all 2020 submissions

- **LLM-powered program generation**: Use LLMs (e.g., GPT-4o) to generate Python programs
  - Example: Ryan Greenblatt - 42% on public eval
  - Approach: Generate thousands of candidate programs, evaluate with code interpreter
  - Requires: Significant prompt engineering, deterministic evaluation

- **LLM-guided DSL search**: Use LLM to guide search within DSL
  - Example: Simon Ouellette
  - Benefit: Reduces search space, improves efficiency

- **LLM-powered iterative debugging**: Refine/debug heuristically-generated programs
  - Example: Greenblatt's iterative approach

- **Not yet tried but expected to work well**: Specialist deep learning models guiding branching decisions (like AlphaProof)

### 2. Test-Time Training (TTT) / Test-Time Fine-Tuning (TTFT)
**Goal**: Adapt pretrained LLM to specific task at inference time

**Key insight**: "Conceptually similar to program search, at opposite end of memorization/recombination spectrum"
- Program search: Deep recombination of small set of generic primitives
- TTT: Shallow recombination of vast number of specialized building blocks (vector functions in weights)

**Critical components**:
- **Data augmentation**: Color permutations, geometric transforms, positional augmentations
- **Alternative datasets**: Re-ARC (infinite sampling), ARC-Heavy/ARC-Potpourri (400K tasks)
- **Fine-tuning strategies**: Both LoRA and full fine-tuning explored
- **Specialized architectures**: 2D attention mechanisms, 2D position encodings

**Examples**:
- **MindsAI**: 33% → 55.5%, pioneered TTT for ARC-AGI (2023), Salesforce T5-based
- **the ARChitects**: 53.5% (1st place Kaggle), NeMo-Minitron-8B, novel stability-based selection
- **Akyürek et al.**: 47.5% semi-private / 62.8% public, 8B parameter model
- **OmniARC (Barbadillo)**: 40% (2nd place), Qwen2.5-0.5B-Instruct

**Variant**: **Latent space search** (Bonnet & MacFarlane) - search in LLM latent space using random search + gradient descent

### 3. Hybrid: Combining Induction + Transduction
**Why needed**: Each approach solves significantly distinct task sets

**Key paper**: Li et al., "Combining Induction and Transduction for Abstract Reasoning" (1st place paper award)

**Evidence**: Best induction-only and transduction-only score ~40%; only ensembles compete for SOTA (53-55%)

**Examples**: All top scorers use hybrids:
- the ARChitects (53.5%)
- Barbadillo (40%)
- Jeremy Berman (53.6% semi-private)
- Akyürek et al. (47.5% semi-private)

## Top Performing Methods

### Competition Winners (Kaggle - 12hr, single P100 GPU, no internet)
1. **the ARChitects**: 53.5%
   - Approach: TTT + hybrid
   - Architecture: NeMo-Minitron-8B
   - Novel contribution: Solution stability under augmentations as selection criterion

2. **Guillermo Barbadillo (OmniARC)**: 40%
   - Approach: TTT + program synthesis ensemble
   - Model: Qwen2.5-0.5B-Instruct

3. **alijs (Agnis Liukis)**: 40%
   - Approach: Brute-force DSL search

4-5. **William Wu, PoohAI**: 37%

**Not eligible (didn't open-source)**: MindsAI - 55.5% (highest score)

### Public Leaderboard (1000x more compute, $10K API budget, internet access)
1. **Jeremy Berman**: 53.6% semi-private, 58.5% public
2. **Akyürek et al.**: 47.5% semi-private, 62.8% public
3. **Ryan Greenblatt**: 43% semi-private, 42% public (LLM-guided program synthesis)
4. **OpenAI o1-preview**: 18% semi-private, 21% public (pass@1)
5. **Claude 3.5 Sonnet**: 14% semi-private, 21% public (pass@1)

### Paper Awards
1. **First**: Li et al., "Combining Induction and Transduction for Abstract Reasoning"
2. **Second**: Akyürek et al., "The Surprising Effectiveness of Test-Time Training for Abstract Reasoning"
3. **Third**: Bonnet & Macfarlane, "Searching Latent Program Spaces"

## Key Quotes

> "This stark gap highlights the inability of the classical deep learning paradigm to generalize to novel tasks."
- Context: Discussing the fact that no static inference transduction solution scores above 11%, while TTT-based approaches reach 55%+

> "From 2020 to early 2024, the field of AI research was dominated by the scaling up of deep learning systems, which increased task-specific skills but did not improve the ability to tackle tasks without available training data at training time (i.e., general intelligence). Our view is that progress towards AGI had stalled during this period."
- Context: Explaining why ARC-AGI remained at 33% for years despite LLM advances

> "Surprisingly, both the competition and secondary public leaderboard top scores tracked closely. This suggests algorithmic improvements towards AGI hold significant power and that massive compute may not be necessary in order to beat ARC-AGI."
- Context: Comparing Kaggle ($10 compute) vs Public leaderboard ($10K compute) - both achieved ~53-55%

> "Today, all top LLM-based transduction approaches for ARC-AGI leverage TTT, and there does not exist any static inference-style transduction solution that scores above 11%."
- Context: Establishing TTT as essential for LLM-based approaches

> "TTT can be seen as conceptually similar to program search, albeit at the opposite end of the memorization/recombination spectrum. Both involve recombining pre-existing building blocks to solve a task."
- Context: Unifying view of TTT and program synthesis

> "We expect that program synthesis, together with closely related test-time search techniques, will be adopted by every frontier AI system over the next 12 to 24 months."
- Context: Predicting future of AI systems (prediction made in late 2024)

> "For instance, we estimate that an 85% ARC-AGI score could be achieved by an approach like Greenblatt's when generating, evaluating, and debugging approximately 100,000,000 programs per task, which would represent a multi-million dollar compute budget to solve 100 tasks."
- Context: Discussing compute scaling for program synthesis - highlighting need for efficiency reporting

> "The defining characteristic of the benchmark is that it should not be possible to prepare for any of the tasks in advance. Every task in the dataset follows a different logic."
- Context: Core philosophy of ARC-AGI

> "ARC-AGI tasks do not require specialized world knowledge (e.g., historical facts) nor language to solve. The only assumed prior knowledge is Core Knowledge."
- Context: Why ARC-AGI is different from other benchmarks

## Relevance to ETRM

### Where ETRM Fits
**ETRM is a transduction approach** that falls between classical deep learning and TTT:
- Uses demonstration examples (like TTT) but encodes them through a learned encoder (not fine-tuning)
- No test-time training/adaptation - uses fixed pretrained encoder + TRM
- Closest analog in this taxonomy: A hybrid between static inference and TTT

### Key Implications for Our Work

1. **The 11% ceiling for static inference**
   - ETRM uses static inference (no TTT) but WITH demonstration encoding
   - Our hypothesis: Encoding demos bridges the gap between 11% ceiling and TTT performance
   - This paper suggests we're testing whether representation learning can replace adaptation

2. **Importance of data augmentation**
   - Both embedding TRM and ETRM use heavy augmentation (~1000x per puzzle)
   - ARChitects' stability-based selection could inform our evaluation
   - Confirms augmentation is not just for data efficiency but for learning invariances

3. **Hybrid approaches dominate**
   - All SOTA use ensemble of induction + transduction
   - ETRM is pure transduction - suggests we may need program synthesis component for SOTA
   - But as a transduction baseline, we're competitive with other transduction-only approaches

4. **Architecture matters**
   - 2D-aware architectures (2D attention, 2D position encoding) help TTT approaches
   - ETRM uses standard Transformer - could benefit from 2D awareness
   - Paper award winner (Puget/NVIDIA) used 2D nGPT

5. **Test-time adaptation is the frontier**
   - TTT represents a paradigm shift (late 2023-2024)
   - ETRM's encoder is a different form of test-time adaptation: computing representations from demos
   - Not fine-tuning, but still adaptive to each puzzle

6. **Comparison baselines**
   - Embedding TRM (~33% pre-2024) represents the classical deep learning paradigm
   - TTT approaches (47-55%) represent the new paradigm
   - ETRM tests whether learned demo encoding can approach TTT without fine-tuning

7. **Dataset concerns for ARC-AGI-2**
   - Current dataset: Only 100 private eval tasks, risk of overfitting
   - 49% achievable by brute-force ensemble (2020 analysis)
   - Our results on ARC-AGI-1 may not fully transfer to ARC-AGI-2 (coming 2025)

### Strategic Positioning
- **Conservative claim**: ETRM improves over embedding baseline by using demo information instead of learned puzzle IDs
- **Ambitious claim**: ETRM achieves TTT-like benefits (task adaptation) through architecture (encoder) rather than optimization (fine-tuning)
- **Realistic expectation**: ETRM should beat static inference (~11%) and classical embedding (~33%), but may not reach TTT SOTA (47-55%) without ensemble

### Future Directions Suggested by Paper
1. Combine ETRM (transduction) with program synthesis (induction) for hybrid approach
2. Explore 2D-aware architectures for ETRM encoder
3. Test ETRM on Re-ARC and ARC-Heavy datasets
4. Compare ETRM efficiency vs TTT (compute budget, parameters updated)
5. Investigate whether ETRM encoder learns similar representations to TTT-adapted models
